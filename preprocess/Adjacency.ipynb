{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4b63ba-4fd7-49e6-8109-21c6cee82659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 16:20:00.984498: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6993894-ad81-4207-a290-4080e4ae5c31",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd08984a-9443-4e70-b3ff-7968bcd3e3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='../model/face_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "face_mesh_connections = mp.solutions.face_mesh.FACEMESH_TESSELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06e817f-29ec-488c-9eea-0408842bfa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories in '../Image_data/DATASET/train':\n",
      "Categories: ['7', '6', '1', '4', '3', '2', '5']\n"
     ]
    }
   ],
   "source": [
    "DIRECTORY = r\"../Image_data/DATASET/train\"\n",
    "CATEGORIES = []\n",
    "\n",
    "try:\n",
    "    folders = os.listdir(DIRECTORY)\n",
    "    print(f\"Directories in '{DIRECTORY}':\")\n",
    "    for folder in folders:\n",
    "        if os.path.isdir(os.path.join(DIRECTORY, folder)):\n",
    "            CATEGORIES.append(folder)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"Categories:\", CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c40b729-2d5e-4b5a-9e40-e2622a3ff180",
   "metadata": {},
   "source": [
    "# Get file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "261c4132-d87b-434b-8460-357ba1754d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定處理類別\n",
    "desired_category = '7'\n",
    "\n",
    "def paths(desired_category):\n",
    "    # Check if the category directory exists\n",
    "    category_path = os.path.join(DIRECTORY, desired_category)\n",
    "\n",
    "    if not os.path.isdir(category_path):\n",
    "        print(f\"Category '{desired_category}' does not exist in '{DIRECTORY}'.\")\n",
    "        # List available categories if the desired one is missing\n",
    "        available_categories = [folder for folder in os.listdir(DIRECTORY) if os.path.isdir(os.path.join(DIRECTORY, folder))]\n",
    "        print(\"Available categories:\", available_categories)\n",
    "        # Raise an error if the category does not exist\n",
    "        raise FileNotFoundError(f\"Category '{category_path}' not found.\")\n",
    "\n",
    "    # Create the output directory structure if it does not exist\n",
    "    output_dir = 'output_data'\n",
    "    landmarks_dir = os.path.join(output_dir, 'landmarks')\n",
    "    connections_dir = os.path.join(output_dir, 'connections')\n",
    "\n",
    "    # Ensure output directories exist\n",
    "    for path in [landmarks_dir, connections_dir]:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            print(f\"Created directory: {path}\")\n",
    "\n",
    "    # Specify the output file paths for landmarks and connections\n",
    "    landmarks = os.path.join(landmarks_dir, f'face_landmarks_{desired_category}.csv')\n",
    "    connections = os.path.join(connections_dir, f'connections_{desired_category}.csv')\n",
    "    \n",
    "    # Return the paths for further use\n",
    "    return landmarks, connections, category_path\n",
    "\n",
    "landmarks_file, connections_file, category_path = paths(desired_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c864848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CSV\n",
    "with open(landmarks_file, 'w', newline='') as landmarks_csv, \\\n",
    "     open(connections_file, 'w', newline='') as connections_csv:\n",
    "    \n",
    "    landmarks_writer = csv.writer(landmarks_csv)\n",
    "    connections_writer = csv.writer(connections_csv)\n",
    "    \n",
    "    landmarks_writer.writerow([\"image_name\", \"category\", \"landmark_index\", \"x\", \"y\", \"z\"])  # Landmarks\n",
    "    connections_writer.writerow([\"image_name\", \"category\", \"point1\", \"point2\"])  # Connections\n",
    "    \n",
    "    # create FaceLandmarker\n",
    "    with FaceLandmarker.create_from_options(options) as landmarker:\n",
    "        folder = category_path\n",
    "        print(f\"Processing category: {desired_category}\")\n",
    "        \n",
    "        # Iterate through each image in the specified category\n",
    "        for image_name in os.listdir(folder):\n",
    "            image_path = os.path.join(folder, image_name)\n",
    "            frame = cv2.imread(image_path)\n",
    "            \n",
    "            if frame is None:\n",
    "                print(f\"Cannot read image: {image_name}\")\n",
    "                continue\n",
    "\n",
    "            h, w = frame.shape[:2]\n",
    "            # to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # create Mediapipe image\n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
    "            \n",
    "            # FaceLandmarker identify face\n",
    "            face_landmarker_result = landmarker.detect(mp_image)\n",
    "            \n",
    "            # Get face feature\n",
    "            face_landmarks_list = face_landmarker_result.face_landmarks\n",
    "\n",
    "            if not face_landmarks_list:\n",
    "                print(f\"No face detected in image: {image_name}\")\n",
    "                continue\n",
    "\n",
    "            # process face feature\n",
    "            for face_landmarks in face_landmarks_list:\n",
    "                # save landmarks\n",
    "                for idx, landmark in enumerate(face_landmarks):\n",
    "                    x = landmark.x * w\n",
    "                    y = landmark.y * h\n",
    "                    z = landmark.z * w\n",
    "                    landmarks_writer.writerow([image_name, desired_category, idx, x, y, z])\n",
    "                \n",
    "                # save connection\n",
    "                for connection in face_mesh_connections:\n",
    "                    point1 = connection[0]\n",
    "                    point2 = connection[1]\n",
    "                    connections_writer.writerow([image_name, desired_category, point1, point2])\n",
    "            \n",
    "            print(f\"Processed: {image_name} in category {desired_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86937ed-a6ab-4856-bcf0-bcaa71082d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_file = f'output_data/landmarks/face_landmarks_{desired_category}.csv'\n",
    "connections_file = f'output_data/connections/connections_{desired_category}.csv'\n",
    "\n",
    "landmarks_df = pd.read_csv(landmarks_file)\n",
    "connections_df = pd.read_csv(connections_file)\n",
    "\n",
    "output_folder = f'output_data/adjacency/adjacency_{desired_category}'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ec74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'image_name' column is not present in connections data, retrieve connection indices in advance\n",
    "if 'image_name' not in connections_df.columns:\n",
    "    point_indices_1 = connections_df['point1'].astype(int).values\n",
    "    point_indices_2 = connections_df['point2'].astype(int).values\n",
    "else:\n",
    "    connections_grouped = connections_df.groupby('image_name')\n",
    "\n",
    "for image_name in landmarks_df['image_name'].unique():\n",
    "    # Filter landmarks for the current image\n",
    "    image_landmarks_df = landmarks_df[landmarks_df['image_name'] == image_name].reset_index(drop=True)\n",
    "    \n",
    "    # Extract coordinates and the number of landmarks for the image\n",
    "    points_coordinates = image_landmarks_df[['x', 'y', 'z']].values\n",
    "    num_points = len(points_coordinates)\n",
    "    \n",
    "    # Initialize the adjacency matrix\n",
    "    adjacency_matrix = np.zeros((num_points, num_points))\n",
    "    \n",
    "    if 'image_name' in connections_df.columns:\n",
    "        # Filter connection data for the current image\n",
    "        if image_name in connections_grouped.groups:\n",
    "            image_connections_df = connections_grouped.get_group(image_name)\n",
    "            point_indices_1 = image_connections_df['point1'].astype(int).values\n",
    "            point_indices_2 = image_connections_df['point2'].astype(int).values\n",
    "        else:\n",
    "            print(f\"No connections found for image: {image_name}\")\n",
    "            continue\n",
    "    else:\n",
    "        pass  # Already retrieved outside, no need to repeat\n",
    "\n",
    "    # Ensure indices are within valid range\n",
    "    valid_indices = (point_indices_1 < num_points) & (point_indices_2 < num_points)\n",
    "    point_indices_1 = point_indices_1[valid_indices]\n",
    "    point_indices_2 = point_indices_2[valid_indices]\n",
    "    \n",
    "    # Retrieve the corresponding coordinates\n",
    "    coords1 = points_coordinates[point_indices_1]\n",
    "    coords2 = points_coordinates[point_indices_2]\n",
    "    \n",
    "    # Compute distances for all connection pairs\n",
    "    distances = np.linalg.norm(coords1 - coords2, axis=1)\n",
    "    \n",
    "    # Fill the adjacency matrix with distances\n",
    "    adjacency_matrix[point_indices_1, point_indices_2] = distances\n",
    "    adjacency_matrix[point_indices_2, point_indices_1] = distances  # Symmetric\n",
    "    \n",
    "    adjacency_df = pd.DataFrame(adjacency_matrix)\n",
    "    output_path = os.path.join(output_folder, f'adjacency_matrix_{image_name}.csv')\n",
    "    adjacency_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved adjacency matrix for {image_name} to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb387f6-5509-480c-bd3f-fa8643304513",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e2fc01b-84e7-441d-82f5-3666bb63c49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All adjacency matrices have corresponding image files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directories for images and adjacency matrices\n",
    "IMAGE_DIRECTORY = r\"../Image_data/DATASET/train/\" + desired_category\n",
    "ADJACENCY_DIRECTORY = r\"output_data/adjacency/adjacency_\" + desired_category\n",
    "\n",
    "def verify_file_pairing(image_dir, adjacency_dir):\n",
    "    \"\"\"\n",
    "    Verify if each adjacency matrix file has a corresponding image file.\n",
    "    \"\"\"\n",
    "    # List all adjacency matrix files\n",
    "    adjacency_files = [f for f in os.listdir(adjacency_dir) if f.endswith('.csv')]\n",
    "\n",
    "    unmatched_files = []\n",
    "\n",
    "    for adjacency_file in adjacency_files:\n",
    "        # Extract the base name without extensions for matching\n",
    "        base_name = os.path.splitext(adjacency_file.replace('adjacency_matrix_', '').replace('.csv', ''))[0]\n",
    "\n",
    "        # Construct the corresponding image file name\n",
    "        image_file = f\"{base_name}.jpg\"\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            unmatched_files.append((adjacency_file, image_file))\n",
    "\n",
    "    if unmatched_files:\n",
    "        print(\"The following adjacency matrices do not have matching image files:\")\n",
    "        for adj, img in unmatched_files:\n",
    "            print(f\"Adjacency Matrix: {adj} | Expected Image: {img}\")\n",
    "    else:\n",
    "        print(\"All adjacency matrices have corresponding image files.\")\n",
    "\n",
    "# Run the verification\n",
    "verify_file_pairing(IMAGE_DIRECTORY, ADJACENCY_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33ef47-8a3f-4073-9eca-f591ec3f43d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
