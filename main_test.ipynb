{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68255679-c372-4ffc-a12b-e4b65248873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from model import *\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from scipy.sparse import coo_matrix\n",
    "from utils import *\n",
    "import random\n",
    "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea0e09bf-e2c8-4ed3-b421-0025113527e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "dir_1 = './output_data/adjacency/adjacency_1'\n",
    "dir_2 = './output_data/adjacency/adjacency_2'\n",
    "dir_3 = './output_data/adjacency/adjacency_3'\n",
    "dir_4 = './output_data/adjacency/adjacency_4'\n",
    "dir_5 = './output_data/adjacency/adjacency_5'\n",
    "dir_6 = './output_data/adjacency/adjacency_6'\n",
    "dir_7 = './output_data/adjacency/adjacency_7'\n",
    "\n",
    "image_dir = './Image_data/DATASET/train'\n",
    "\n",
    "data_dict = {'1': [], '2': [], '3': [], '4': [], '5': [], '6': [], '7': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f8a9905-4a05-4491-9e5a-08e4e31c8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(dir_1):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(dir_1, filename)\n",
    "        unique_id = filename.replace('adjacency_matrix_', '').replace('.csv', '')\n",
    "        image_path = os.path.join(image_dir, f'1/{unique_id}')\n",
    "        data = process_adj_matrix(file_path, image_path)\n",
    "        data.y = torch.tensor([0])\n",
    "        data_dict['1'].append(data)\n",
    "\n",
    "for filename in os.listdir(dir_2):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(dir_2, filename)\n",
    "        unique_id = filename.replace('adjacency_matrix_', '').replace('.csv', '')\n",
    "        image_path = os.path.join(image_dir, f'2/{unique_id}')\n",
    "        data = process_adj_matrix(file_path, image_path)\n",
    "        data.y = torch.tensor([1])\n",
    "        data_dict['2'].append(data)\n",
    "\n",
    "for filename in os.listdir(dir_3):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(dir_3, filename)\n",
    "        unique_id = filename.replace('adjacency_matrix_', '').replace('.csv', '')\n",
    "        image_path = os.path.join(image_dir, f'3/{unique_id}')\n",
    "        data = process_adj_matrix(file_path, image_path)\n",
    "        data.y = torch.tensor([2])\n",
    "        data_dict['3'].append(data)\n",
    "        \n",
    "for filename in os.listdir(dir_4):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(dir_4, filename)\n",
    "        unique_id = filename.replace('adjacency_matrix_', '').replace('.csv', '')\n",
    "        image_path = os.path.join(image_dir, f'4/{unique_id}')\n",
    "        data = process_adj_matrix(file_path, image_path)\n",
    "        data.y = torch.tensor([2])\n",
    "        data_dict['4'].append(data)\n",
    "\n",
    "for filename in os.listdir(dir_5):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(dir_5, filename)\n",
    "        unique_id = filename.replace('adjacency_matrix_', '').replace('.csv', '')\n",
    "        image_path = os.path.join(image_dir, f'5/{unique_id}')\n",
    "        data = process_adj_matrix(file_path, image_path)\n",
    "        data.y = torch.tensor([1])\n",
    "        data_dict['5'].append(data)\n",
    "\n",
    "for filename in os.listdir(dir_6):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(dir_6, filename)\n",
    "        unique_id = filename.replace('adjacency_matrix_', '').replace('.csv', '')\n",
    "        image_path = os.path.join(image_dir, f'6/{unique_id}')\n",
    "        data = process_adj_matrix(file_path, image_path)\n",
    "        data.y = torch.tensor([2])\n",
    "        data_dict['6'].append(data)\n",
    "        \n",
    "for filename in os.listdir(dir_7):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(dir_7, filename)\n",
    "        unique_id = filename.replace('adjacency_matrix_', '').replace('.csv', '')\n",
    "        image_path = os.path.join(image_dir, f'7/{unique_id}')\n",
    "        data = process_adj_matrix(file_path, image_path)\n",
    "        data.y = torch.tensor([2])\n",
    "        data_dict['7'].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a00c66e9-4090-485c-bd4f-58f84e4e8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = data_dict['1'] + data_dict['2'] + data_dict['3'] + data_dict['4'] + data_dict['5'] + data_dict['6'] + data_dict['7']\n",
    "\n",
    "batch_size = 64\n",
    "loader = GeoDataLoader(data_list, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_node_features = data_list[0].x.shape[1]  # Number of node features\n",
    "hidden_channels = 64\n",
    "\n",
    "model = Net_Alex(num_node_features, hidden_channels).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20cc46-96b7-471c-abc9-09ad3da857ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch in loader:\n",
    "        batch.x = batch.x.to(device)\n",
    "        batch.edge_index = batch.edge_index.to(device)\n",
    "        batch.edge_weight = batch.edge_weight.to(device)\n",
    "        batch.batch = batch.batch.to(device)\n",
    "        batch.y = batch.y.to(device)\n",
    "        batch.image_features = batch.image_features.to(device)  # Image tensor to device\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_weight, batch.batch, batch.image_features)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, pred = out.max(dim=1)\n",
    "        correct += (pred == batch.y).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / len(data_list)  # Overall accuracy\n",
    "    print(f'Epoch {epoch}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
